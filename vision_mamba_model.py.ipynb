{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerlshin/anaconda3/envs/gnn/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/jerlshin/anaconda3/envs/gnn/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/jerlshin/anaconda3/envs/gnn/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/jerlshin/anaconda3/envs/gnn/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import os\n",
    "import argparse\n",
    "import ast\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision import models, datasets\n",
    "from torchvision import transforms as Transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import auc, precision_recall_curve, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import pipeline, AutoModel\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config, resolve_model_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    MODEL_NAME = \"hf_hub:timm/mambaout_base.in1k\"\n",
    "    NUM_CLASSES = 14\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 50\n",
    "    LR = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "    \n",
    "    SEED = 42\n",
    "    SAVE_DIR = \"./checkpoints\"\n",
    "    LOG_DIR = \"./logs\"\n",
    "    \n",
    "    NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = configparser.ConfigParser()\n",
    "config_parser.read(\"/home/model/visible_images_config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"visible_images\" in config_parser and \"labels\" in config_parser:\n",
    "    images_path = config_parser[\"visible_images\"][\"data\"]\n",
    "    labels = config_parser[\"labels\"][\"label_path\"]\n",
    "else:\n",
    "    raise ValueError(\"Dataset configuration not found in config_parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'class_name', 'class_id', 'rad_id', 'x_min', 'y_min',\n",
       "       'x_max', 'y_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rad_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "x_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_max",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "27918c6c-36f2-4c89-ad2a-2857a87dbf6e",
       "rows": [
        [
         "0",
         "50a418190bc3fb1ef1633bf9678929b3",
         "No finding",
         "14",
         "R11",
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "21a10246a5ec7af151081d0cd6d65dc9",
         "No finding",
         "14",
         "R7",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "9a5094b2563a1ef3ff50dc5c7ff71345",
         "Cardiomegaly",
         "3",
         "R10",
         "691.0",
         "1375.0",
         "1653.0",
         "1831.0"
        ],
        [
         "3",
         "051132a778e61a86eb147c7c6f564dfe",
         "Aortic enlargement",
         "0",
         "R10",
         "1264.0",
         "743.0",
         "1611.0",
         "1019.0"
        ],
        [
         "4",
         "063319de25ce7edb9b1c6b8881290140",
         "No finding",
         "14",
         "R10",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>rad_id</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a418190bc3fb1ef1633bf9678929b3</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21a10246a5ec7af151081d0cd6d65dc9</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>3</td>\n",
       "      <td>R10</td>\n",
       "      <td>691.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>1831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
       "      <td>Aortic enlargement</td>\n",
       "      <td>0</td>\n",
       "      <td>R10</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>063319de25ce7edb9b1c6b8881290140</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id          class_name  class_id rad_id  \\\n",
       "0  50a418190bc3fb1ef1633bf9678929b3          No finding        14    R11   \n",
       "1  21a10246a5ec7af151081d0cd6d65dc9          No finding        14     R7   \n",
       "2  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly         3    R10   \n",
       "3  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement         0    R10   \n",
       "4  063319de25ce7edb9b1c6b8881290140          No finding        14    R10   \n",
       "\n",
       "    x_min   y_min   x_max   y_max  \n",
       "0     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN  \n",
       "2   691.0  1375.0  1653.0  1831.0  \n",
       "3  1264.0   743.0  1611.0  1019.0  \n",
       "4     NaN     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c837a5ad-2c23-4dd8-89ad-77219149bb3e",
       "rows": [
        [
         "0",
         "50a418190bc3fb1ef1633bf9678929b3",
         "No finding"
        ],
        [
         "1",
         "21a10246a5ec7af151081d0cd6d65dc9",
         "No finding"
        ],
        [
         "2",
         "9a5094b2563a1ef3ff50dc5c7ff71345",
         "Cardiomegaly"
        ],
        [
         "3",
         "051132a778e61a86eb147c7c6f564dfe",
         "Aortic enlargement"
        ],
        [
         "4",
         "063319de25ce7edb9b1c6b8881290140",
         "No finding"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a418190bc3fb1ef1633bf9678929b3</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21a10246a5ec7af151081d0cd6d65dc9</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
       "      <td>Aortic enlargement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>063319de25ce7edb9b1c6b8881290140</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id          class_name\n",
       "0  50a418190bc3fb1ef1633bf9678929b3          No finding\n",
       "1  21a10246a5ec7af151081d0cd6d65dc9          No finding\n",
       "2  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly\n",
       "3  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement\n",
       "4  063319de25ce7edb9b1c6b8881290140          No finding"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = label_df.drop(columns=[\"rad_id\", \"x_min\", \"x_max\", \"y_min\", \"y_max\", \"class_id\"])\n",
    "\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f84ab48d-fb39-49dd-b34e-b37ceb137ee6",
       "rows": [
        [
         "0",
         "50a418190bc3fb1ef1633bf9678929b3",
         "No finding"
        ],
        [
         "1",
         "21a10246a5ec7af151081d0cd6d65dc9",
         "No finding"
        ],
        [
         "4",
         "063319de25ce7edb9b1c6b8881290140",
         "No finding"
        ],
        [
         "12",
         "5550a493b1c4554da469a072fdfab974",
         "No finding"
        ],
        [
         "13",
         "869f39afbdd8783b531530942eda8bad",
         "No finding"
        ],
        [
         "15",
         "f55460fccf2d3c591f57f9c0de2c37c2",
         "No finding"
        ],
        [
         "16",
         "cdbacab6bf30170ef0ba9fd1d195d270",
         "No finding"
        ],
        [
         "21",
         "c6e0ab2470d98a6a8c701e774df929cc",
         "No finding"
        ],
        [
         "23",
         "5e56b7582a7cb3616e69cf95cb544a17",
         "No finding"
        ],
        [
         "24",
         "fc06d54844aee54acd87466f59acfc5b",
         "No finding"
        ],
        [
         "25",
         "5ce53167cb33fa63c59af857d7236416",
         "No finding"
        ],
        [
         "26",
         "63d5b6f568f005932b9246bcb40eee68",
         "No finding"
        ],
        [
         "28",
         "9b85b7ef757927db44393d03083a757c",
         "No finding"
        ],
        [
         "29",
         "fdd5c663764c4f333a42250ad5a67790",
         "No finding"
        ],
        [
         "30",
         "b911c2fdb0b80d9c7214a859aced0a8a",
         "No finding"
        ],
        [
         "32",
         "5d03f4c2d353a2ddfdc4ba932e5b1029",
         "No finding"
        ],
        [
         "33",
         "42d472bdda3ad93dac63c8e5e29977bb",
         "No finding"
        ],
        [
         "34",
         "2b1293d9c276e5439e499f58ce2e31ab",
         "No finding"
        ],
        [
         "35",
         "e4b12e030788bbd71f7ad72fa1ee5a71",
         "No finding"
        ],
        [
         "38",
         "a2a8eb578628cb2c353e6b6dc311de5c",
         "No finding"
        ],
        [
         "44",
         "ad2367bde2706f692c2e1a1d12c492b9",
         "No finding"
        ],
        [
         "46",
         "d86c7405606f965ab7300ef1eacbcacc",
         "No finding"
        ],
        [
         "49",
         "77c3750fdc5ae970693a6d7080ef702c",
         "No finding"
        ],
        [
         "50",
         "d35342287accb789782fee0e4a8b1031",
         "No finding"
        ],
        [
         "54",
         "73a4407a2df891526e94ba4541023f49",
         "No finding"
        ],
        [
         "57",
         "9fbeb619ac9a406375ef5d6447227b5b",
         "No finding"
        ],
        [
         "58",
         "82bc4f8652641af7cf061ab4b6ead271",
         "No finding"
        ],
        [
         "62",
         "cc9b6ee01a01702434ad789eef9432fb",
         "No finding"
        ],
        [
         "64",
         "e3ac18fd134bcb699760db4ef362e14f",
         "No finding"
        ],
        [
         "65",
         "2561ba15f063a8e3a0322ad943738bb5",
         "No finding"
        ],
        [
         "67",
         "764205f702d380f8a4da5cffa538f48d",
         "No finding"
        ],
        [
         "72",
         "59979178089975839bbc17e5cb88faf2",
         "No finding"
        ],
        [
         "77",
         "0890c2d68d17561848b25c61fb1da200",
         "No finding"
        ],
        [
         "78",
         "0ec928d72a4d206fe1b87ab683171004",
         "No finding"
        ],
        [
         "85",
         "b76a2de0cd2d3a9625e7df015ccf3816",
         "No finding"
        ],
        [
         "86",
         "2d8289dc0a35bc2c7d3b0afb4d0c25fb",
         "No finding"
        ],
        [
         "87",
         "20294a6c521b2ffc8ee2e7e1cac1fc50",
         "No finding"
        ],
        [
         "88",
         "b5a0555e2c623c355901601a907c6342",
         "No finding"
        ],
        [
         "90",
         "b31653be8e7a18487acbed2f8260c5ef",
         "No finding"
        ],
        [
         "91",
         "2b73e82661e82f7c15c3ddaa15926d35",
         "No finding"
        ],
        [
         "92",
         "7b6c00f300b0aa2c2c2bd0b51edea43a",
         "No finding"
        ],
        [
         "94",
         "890c7efc23b2a23439c301dca707c33f",
         "No finding"
        ],
        [
         "96",
         "69f5d29210d98df18120534adb990291",
         "No finding"
        ],
        [
         "97",
         "189e409214f5a4639d821a34064d9140",
         "No finding"
        ],
        [
         "101",
         "c438d1ff72b5848adb7a063ebc90cd12",
         "No finding"
        ],
        [
         "102",
         "abdc33338a055571bf9fae0f09eb0bd5",
         "No finding"
        ],
        [
         "103",
         "d40b35c2f594b89524c67af46ac342f6",
         "No finding"
        ],
        [
         "105",
         "6ec4a6b5d3180220d6debf958d147c25",
         "No finding"
        ],
        [
         "108",
         "c113ff68c59ef8d40cd4c0bd6e021a6e",
         "No finding"
        ],
        [
         "110",
         "469999b0e3acee129f96aceaa99eba0d",
         "No finding"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 31818
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a418190bc3fb1ef1633bf9678929b3</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21a10246a5ec7af151081d0cd6d65dc9</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>063319de25ce7edb9b1c6b8881290140</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5550a493b1c4554da469a072fdfab974</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>869f39afbdd8783b531530942eda8bad</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67905</th>\n",
       "      <td>955f258cc29153f996ee6716218c1196</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67909</th>\n",
       "      <td>936fd5cff1c058d39817a08f58b72cae</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67910</th>\n",
       "      <td>ca7e72954550eeb610fe22bf0244b7fa</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67911</th>\n",
       "      <td>aa17d5312a0fb4a2939436abca7f9579</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67913</th>\n",
       "      <td>5e272e3adbdaafb07a7e84a9e62b1a4c</td>\n",
       "      <td>No finding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31818 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id  class_name\n",
       "0      50a418190bc3fb1ef1633bf9678929b3  No finding\n",
       "1      21a10246a5ec7af151081d0cd6d65dc9  No finding\n",
       "4      063319de25ce7edb9b1c6b8881290140  No finding\n",
       "12     5550a493b1c4554da469a072fdfab974  No finding\n",
       "13     869f39afbdd8783b531530942eda8bad  No finding\n",
       "...                                 ...         ...\n",
       "67905  955f258cc29153f996ee6716218c1196  No finding\n",
       "67909  936fd5cff1c058d39817a08f58b72cae  No finding\n",
       "67910  ca7e72954550eeb610fe22bf0244b7fa  No finding\n",
       "67911  aa17d5312a0fb4a2939436abca7f9579  No finding\n",
       "67913  5e272e3adbdaafb07a7e84a9e62b1a4c  No finding\n",
       "\n",
       "[31818 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[label_df[\"class_name\"] == \"No finding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df[label_df[\"class_name\"] != \"No finding\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Cardiomegaly', 'Aortic enlargement', 'Pleural thickening', 'ILD',\n",
       "        'Nodule/Mass', 'Pulmonary fibrosis', 'Lung Opacity', 'Atelectasis',\n",
       "        'Other lesion', 'Infiltration', 'Pleural effusion',\n",
       "        'Calcification', 'Consolidation', 'Pneumothorax'], dtype=object),\n",
       " 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[\"class_name\"].unique(), len(label_df[\"class_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b2b48d83-000e-4f39-83e7-073196c19796",
       "rows": [
        [
         "0",
         "9a5094b2563a1ef3ff50dc5c7ff71345",
         "Cardiomegaly"
        ],
        [
         "1",
         "051132a778e61a86eb147c7c6f564dfe",
         "Aortic enlargement"
        ],
        [
         "2",
         "1c32170b4af4ce1a3030eb8167753b06",
         "Pleural thickening"
        ],
        [
         "3",
         "0c7a38f293d5f5e4846aa4ca6db4daf1",
         "ILD"
        ],
        [
         "4",
         "47ed17dcb2cbeec15182ed335a8b5a9e",
         "Nodule/Mass"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
       "      <td>Aortic enlargement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c32170b4af4ce1a3030eb8167753b06</td>\n",
       "      <td>Pleural thickening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c7a38f293d5f5e4846aa4ca6db4daf1</td>\n",
       "      <td>ILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47ed17dcb2cbeec15182ed335a8b5a9e</td>\n",
       "      <td>Nodule/Mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id          class_name\n",
       "0  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly\n",
       "1  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement\n",
       "2  1c32170b4af4ce1a3030eb8167753b06  Pleural thickening\n",
       "3  0c7a38f293d5f5e4846aa4ca6db4daf1                 ILD\n",
       "4  47ed17dcb2cbeec15182ed335a8b5a9e         Nodule/Mass"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = sorted(set(label_df[\"class_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aortic enlargement',\n",
       " 'Atelectasis',\n",
       " 'Calcification',\n",
       " 'Cardiomegaly',\n",
       " 'Consolidation',\n",
       " 'ILD',\n",
       " 'Infiltration',\n",
       " 'Lung Opacity',\n",
       " 'Nodule/Mass',\n",
       " 'Other lesion',\n",
       " 'Pleural effusion',\n",
       " 'Pleural thickening',\n",
       " 'Pneumothorax',\n",
       " 'Pulmonary fibrosis']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_idx_label = {class_name: idx for idx, class_name in enumerate(unique_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aortic enlargement': 0,\n",
       " 'Atelectasis': 1,\n",
       " 'Calcification': 2,\n",
       " 'Cardiomegaly': 3,\n",
       " 'Consolidation': 4,\n",
       " 'ILD': 5,\n",
       " 'Infiltration': 6,\n",
       " 'Lung Opacity': 7,\n",
       " 'Nodule/Mass': 8,\n",
       " 'Other lesion': 9,\n",
       " 'Pleural effusion': 10,\n",
       " 'Pleural thickening': 11,\n",
       " 'Pneumothorax': 12,\n",
       " 'Pulmonary fibrosis': 13}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df[\"class_id\"] = label_df[\"class_name\"].map(map_idx_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Cardiomegaly', 'Aortic enlargement', 'Pleural thickening', 'ILD',\n",
       "        'Nodule/Mass', 'Pulmonary fibrosis', 'Lung Opacity', 'Atelectasis',\n",
       "        'Other lesion', 'Infiltration', 'Pleural effusion',\n",
       "        'Calcification', 'Consolidation', 'Pneumothorax'], dtype=object),\n",
       " array([ 3,  0, 11,  5,  8, 13,  7,  1,  9,  6, 10,  2,  4, 12]),\n",
       " 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[\"class_name\"].unique(), label_df[\"class_id\"].unique(), len(label_df[\"class_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from Hugging Face hub (timm/mambaout_base.in1k)\n",
      "[timm/mambaout_base.in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "# model to train\n",
    "\n",
    "model_name = \"hf_hub:timm/mambaout_base.in1k\"\n",
    "\n",
    "model = timm.create_model(model_name=model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpHead(\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Sequential(\n",
       "    (fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (act): GELU(approximate='none')\n",
       "    (norm): LayerNorm((3072,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=3072, out_features=1000, bias=True)\n",
       "  (head_dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3072, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.head.fc.in_features\n",
    "\n",
    "model.head.fc = nn.Linear(in_features, Config.NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image = torch.randn((1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(dummy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, channels, height, width = 4, 3, 224, 224\n",
    "\n",
    "# img = torch.randn(batch_size, channels, height, width)\n",
    "# img = torch.randint(low=0, high=255, size=(batch_size, channels, height, width), dtype=torch.uint8)\n",
    "\n",
    "# output = model(transforms(img))                       # (batch_size, num_features)\n",
    "\n",
    "# \"\"\"Granular model\"\"\"\n",
    "# output = model.forward_features(transforms(img))        # (1, 7, 7, 768)\n",
    "# output = model.forward_head(output, pre_logits=True)    # (1, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: stem.conv1.weight, Shape: torch.Size([64, 3, 3, 3]), Trainable: True\n",
      "Parameter name: stem.conv1.bias, Shape: torch.Size([64]), Trainable: True\n",
      "Parameter name: stem.norm1.weight, Shape: torch.Size([64]), Trainable: True\n",
      "Parameter name: stem.norm1.bias, Shape: torch.Size([64]), Trainable: True\n",
      "Parameter name: stem.conv2.weight, Shape: torch.Size([128, 64, 3, 3]), Trainable: True\n",
      "Parameter name: stem.conv2.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stem.norm2.weight, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stem.norm2.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.norm.weight, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.norm.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.fc1.weight, Shape: torch.Size([682, 128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.fc1.bias, Shape: torch.Size([682]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.conv.weight, Shape: torch.Size([128, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.conv.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.fc2.weight, Shape: torch.Size([128, 341]), Trainable: True\n",
      "Parameter name: stages.0.blocks.0.fc2.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.norm.weight, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.norm.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.fc1.weight, Shape: torch.Size([682, 128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.fc1.bias, Shape: torch.Size([682]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.conv.weight, Shape: torch.Size([128, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.conv.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.fc2.weight, Shape: torch.Size([128, 341]), Trainable: True\n",
      "Parameter name: stages.0.blocks.1.fc2.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.norm.weight, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.norm.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.fc1.weight, Shape: torch.Size([682, 128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.fc1.bias, Shape: torch.Size([682]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.conv.weight, Shape: torch.Size([128, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.conv.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.fc2.weight, Shape: torch.Size([128, 341]), Trainable: True\n",
      "Parameter name: stages.0.blocks.2.fc2.bias, Shape: torch.Size([128]), Trainable: True\n",
      "Parameter name: stages.1.downsample.conv.weight, Shape: torch.Size([256, 128, 3, 3]), Trainable: True\n",
      "Parameter name: stages.1.downsample.conv.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.downsample.norm.weight, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.downsample.norm.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.norm.weight, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.norm.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.fc1.weight, Shape: torch.Size([1364, 256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.fc1.bias, Shape: torch.Size([1364]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.conv.weight, Shape: torch.Size([256, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.conv.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.fc2.weight, Shape: torch.Size([256, 682]), Trainable: True\n",
      "Parameter name: stages.1.blocks.0.fc2.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.norm.weight, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.norm.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.fc1.weight, Shape: torch.Size([1364, 256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.fc1.bias, Shape: torch.Size([1364]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.conv.weight, Shape: torch.Size([256, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.conv.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.fc2.weight, Shape: torch.Size([256, 682]), Trainable: True\n",
      "Parameter name: stages.1.blocks.1.fc2.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.norm.weight, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.norm.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.fc1.weight, Shape: torch.Size([1364, 256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.fc1.bias, Shape: torch.Size([1364]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.conv.weight, Shape: torch.Size([256, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.conv.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.fc2.weight, Shape: torch.Size([256, 682]), Trainable: True\n",
      "Parameter name: stages.1.blocks.2.fc2.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.norm.weight, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.norm.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.fc1.weight, Shape: torch.Size([1364, 256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.fc1.bias, Shape: torch.Size([1364]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.conv.weight, Shape: torch.Size([256, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.conv.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.fc2.weight, Shape: torch.Size([256, 682]), Trainable: True\n",
      "Parameter name: stages.1.blocks.3.fc2.bias, Shape: torch.Size([256]), Trainable: True\n",
      "Parameter name: stages.2.downsample.conv.weight, Shape: torch.Size([512, 256, 3, 3]), Trainable: True\n",
      "Parameter name: stages.2.downsample.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.downsample.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.downsample.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.0.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.1.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.2.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.3.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.4.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.5.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.6.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.7.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.8.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.9.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.10.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.11.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.12.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.13.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.14.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.15.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.16.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.17.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.18.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.19.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.20.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.21.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.22.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.23.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.24.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.25.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.norm.weight, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.norm.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.fc1.weight, Shape: torch.Size([2730, 512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.fc1.bias, Shape: torch.Size([2730]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.conv.weight, Shape: torch.Size([512, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.conv.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.fc2.weight, Shape: torch.Size([512, 1365]), Trainable: True\n",
      "Parameter name: stages.2.blocks.26.fc2.bias, Shape: torch.Size([512]), Trainable: True\n",
      "Parameter name: stages.3.downsample.conv.weight, Shape: torch.Size([768, 512, 3, 3]), Trainable: True\n",
      "Parameter name: stages.3.downsample.conv.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.downsample.norm.weight, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.downsample.norm.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.norm.weight, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.norm.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.fc1.weight, Shape: torch.Size([4096, 768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.fc1.bias, Shape: torch.Size([4096]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.conv.weight, Shape: torch.Size([768, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.conv.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.fc2.weight, Shape: torch.Size([768, 2048]), Trainable: True\n",
      "Parameter name: stages.3.blocks.0.fc2.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.norm.weight, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.norm.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.fc1.weight, Shape: torch.Size([4096, 768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.fc1.bias, Shape: torch.Size([4096]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.conv.weight, Shape: torch.Size([768, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.conv.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.fc2.weight, Shape: torch.Size([768, 2048]), Trainable: True\n",
      "Parameter name: stages.3.blocks.1.fc2.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.norm.weight, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.norm.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.fc1.weight, Shape: torch.Size([4096, 768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.fc1.bias, Shape: torch.Size([4096]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.conv.weight, Shape: torch.Size([768, 1, 7, 7]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.conv.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.fc2.weight, Shape: torch.Size([768, 2048]), Trainable: True\n",
      "Parameter name: stages.3.blocks.2.fc2.bias, Shape: torch.Size([768]), Trainable: True\n",
      "Parameter name: head.weight, Shape: torch.Size([14, 768]), Trainable: True\n",
      "Parameter name: head.bias, Shape: torch.Size([14]), Trainable: True\n"
     ]
    }
   ],
   "source": [
    "# Iterate over named parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Shape: {param.shape}, Trainable: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 79380810\n"
     ]
    }
   ],
   "source": [
    "# Count trainable parameters\n",
    "total_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=14, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier1(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(classifier1, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = model.head.in_features\n",
    "\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaOut(\n",
       "  (stem): Stem(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (act): GELU(approximate='none')\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): MambaOutStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(512, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier = classifier1(in_features=in_features, num_classes=Config.NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image = torch.randn((1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(dummy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 7, 14])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.forward_features(dummy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 7, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=14, bias=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = label_df[\"class_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cardiomegaly',\n",
       " 'Aortic enlargement',\n",
       " 'Pleural thickening',\n",
       " 'ILD',\n",
       " 'Nodule/Mass',\n",
       " 'Pulmonary fibrosis',\n",
       " 'Lung Opacity',\n",
       " 'Atelectasis',\n",
       " 'Other lesion',\n",
       " 'Infiltration',\n",
       " 'Pleural effusion',\n",
       " 'Calcification',\n",
       " 'Consolidation',\n",
       " 'Pneumothorax']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = timm.data.resolve_data_config(model.default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hf_hub_id': 'timm/mambaout_base.in1k',\n",
       " 'source': 'hf-hub',\n",
       " 'architecture': 'mambaout_base',\n",
       " 'tag': 'in1k',\n",
       " 'custom_load': False,\n",
       " 'input_size': [3, 224, 224],\n",
       " 'test_input_size': [3, 288, 288],\n",
       " 'fixed_input_size': False,\n",
       " 'interpolation': 'bicubic',\n",
       " 'crop_pct': 1.0,\n",
       " 'crop_mode': 'center',\n",
       " 'mean': [0.485, 0.456, 0.406],\n",
       " 'std': [0.229, 0.224, 0.225],\n",
       " 'num_classes': 1000,\n",
       " 'pool_size': [7, 7],\n",
       " 'first_conv': 'stem.conv1',\n",
       " 'classifier': 'head.fc'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transforms = timm.data.transforms_factory.create_transform(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    MaybeToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasett(Dataset):\n",
    "    def __init__(self, image_dir, map_idx_label, label_df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.map_idx_label = map_idx_label\n",
    "        self.label_df = label_df\n",
    "        self.transform = transform\n",
    "        \n",
    "        if \"image_id\" not in label_df.columns or \"class_id\" not in label_df.columns:\n",
    "            raise ValueError(\"label_df must contain 'image_id' and 'class_id' columns\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.label_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row[\"image_id\"] + \".png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        label = row[\"class_id\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn),\n",
       " CenterCrop(size=(224, 224)),\n",
       " MaybeToTensor(),\n",
       " Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_transform_list = list(default_transforms.transforms)\n",
    "\n",
    "default_transform_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmentations = [\n",
    "    # Transforms.RandomHorizontalFlip(),\n",
    "    # Transforms.RandomRotation(15), # rotate +- 15 deg\n",
    "    # Transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "]\n",
    "\n",
    "train_transform = Transforms.Compose(train_augmentations + default_transform_list)\n",
    "\n",
    "val_transform = Transforms.Compose(default_transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    MaybeToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    MaybeToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=Config.NUM_FOLDS, shuffle=True, random_state=Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasett(\n",
    "    image_dir=images_path, \n",
    "    map_idx_label=map_idx_label, \n",
    "    label_df=label_df, \n",
    "    transform=train_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(dataset.label_df[\"class_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = label_df[\"class_id\"].value_counts().sort_index().values\n",
    "\n",
    "total_samples = len(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 14 artists>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_ids = label_df[\"class_id\"].value_counts().sort_index().index\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_ids, class_counts, color='skyblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aortic enlargement': 0,\n",
       " 'Atelectasis': 1,\n",
       " 'Calcification': 2,\n",
       " 'Cardiomegaly': 3,\n",
       " 'Consolidation': 4,\n",
       " 'ILD': 5,\n",
       " 'Infiltration': 6,\n",
       " 'Lung Opacity': 7,\n",
       " 'Nodule/Mass': 8,\n",
       " 'Other lesion': 9,\n",
       " 'Pleural effusion': 10,\n",
       " 'Pleural thickening': 11,\n",
       " 'Pneumothorax': 12,\n",
       " 'Pulmonary fibrosis': 13}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv freq\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "# norm\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(Config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights for Focal Loss: tensor([0.0093, 0.2382, 0.0692, 0.0122, 0.1195, 0.0665, 0.0533, 0.0268, 0.0258,\n",
      "        0.0302, 0.0268, 0.0137, 0.2941, 0.0143])\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Weights for Focal Loss:\", class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focalloss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(focalloss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \n",
    "        num_classes = logits.shape[-1]\n",
    "        \n",
    "        # Ensure targets are in the valid range\n",
    "        targets = targets.long().clamp(0, num_classes - 1)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        targets_one_hot = F.one_hot(targets, num_classes=num_classes).float()\n",
    "\n",
    "        ce_loss = -targets_one_hot * torch.log(probs + 1e-8)\n",
    "        \n",
    "        focal_loss = self.alpha * (1 - probs) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn([4, 7, 7, 14])  # batch size is 2 and in each batch there are 4 elements... and total classes are [-1] 5 in this case\n",
    "\n",
    "targets = torch.tensor([12, 11,  9,  7])\n",
    "alpha = torch.tensor([0.25, 0.5, 0.25])\n",
    "\n",
    "num_classes = logits.shape[-1]\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.long().clamp(0, num_classes - 1)\n",
    "probs = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_one_hot = F.one_hot(targets, num_classes=num_classes).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 11,  9,  7])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 7, 14])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 14])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = focalloss(alpha=alpha, gamma=2.0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1:\n",
    "    def __init__(self, model, dataset, config):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "        self.criterion = focalloss(alpha=class_weights_tensor, gamma=2.0)\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "        self.writer = SummaryWriter(log_dir=config.LOG_DIR)\n",
    "\n",
    "        os.makedirs(config.SAVE_DIR, exist_ok=True)\n",
    "        os.makedirs(config.LOG_DIR, exist_ok=True)\n",
    "\n",
    "        log_file = os.path.join(config.LOG_DIR, \"training.log\")\n",
    "        logging.basicConfig(filename=log_file, level=logging.INFO, \n",
    "                            format=\"%(asctime)s - %(levelname)s - %(message)s\", filemode=\"w\")\n",
    "        self.logger = logging.getLogger()\n",
    "        self.logger.addHandler(logging.StreamHandler())\n",
    "        \n",
    "    def log(self, message):\n",
    "        \"\"\"Prints and logs a message.\"\"\"\n",
    "        self.logger.info(message)\n",
    "        print(message)\n",
    "\n",
    "    def train_one_epoch(self, train_loader, epoch, fold):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Fold {fold}, Epoch {epoch}\", leave=False):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            \n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "        precision = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Train/Loss\", avg_loss, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Train/Accuracy\", accuracy, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Train/Precision\", precision, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Train/Recall\", recall, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Train/F1-Score\", f1, epoch)\n",
    "\n",
    "        self.log(f\"Fold {fold}, Epoch {epoch} - Train Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%, Prec: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")\n",
    "\n",
    "        return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "    def validate(self, val_loader, epoch, fold):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Validation Fold {fold}, Epoch {epoch}\", leave=False):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = running_loss / len(val_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "        precision = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Val/Loss\", avg_loss, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Val/Accuracy\", accuracy, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Val/Precision\", precision, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Val/Recall\", recall, epoch)\n",
    "        self.writer.add_scalar(f\"Fold_{fold}/Val/F1-Score\", f1, epoch)\n",
    "\n",
    "        self.log(f\"Fold {fold}, Epoch {epoch} - Val Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%, Prec: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")\n",
    "\n",
    "        return avg_loss, accuracy, precision, recall, f1, all_labels, all_preds\n",
    "\n",
    "    def plot_confusion_matrix(self, labels, preds):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        class_names = sorted(set(self.dataset.label_df[\"class_name\"]))\n",
    "        df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "\n",
    "        cm_path = os.path.join(self.config.LOG_DIR, \"confusion_matrix.png\")\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "\n",
    "        self.log(f\"Confusion matrix saved at {cm_path}\")\n",
    "\n",
    "    def run_training(self):\n",
    "        skf = StratifiedKFold(n_splits=self.config.NUM_FOLDS, shuffle=True, random_state=self.config.SEED)\n",
    "        labels = self.dataset.label_df[\"class_id\"].values\n",
    "        all_indices = list(skf.split(np.zeros(len(labels)), labels))\n",
    "        test_indices = all_indices[-1]\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        for fold in range(self.config.NUM_FOLDS - 1):\n",
    "            train_indices, val_indices = all_indices[fold]\n",
    "            train_loader = DataLoader(Subset(self.dataset, train_indices), batch_size=self.config.BATCH_SIZE, shuffle=True)\n",
    "            val_loader = DataLoader(Subset(self.dataset, val_indices), batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            for epoch in range(self.config.NUM_EPOCHS):\n",
    "                self.train_one_epoch(train_loader, epoch, fold)\n",
    "                _, val_acc, *_ = self.validate(val_loader, epoch, fold)\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model = self.model.state_dict()\n",
    "\n",
    "        self.model.load_state_dict(best_model)\n",
    "        _, test_indices = test_indices\n",
    "        test_loader = DataLoader(Subset(self.dataset, test_indices), batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
    "        test_loss, test_acc, *_ = self.validate(test_loader, 0, \"Test\")\n",
    "\n",
    "        self.log(f\"\\nFinal Test Set Results -> Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%\")\n",
    "        self.plot_confusion_matrix(test_loader.dataset.targets, test_loader.dataset.targets)\n",
    "\n",
    "        return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaOut(\n",
       "  (stem): Stem(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (act): GELU(approximate='none')\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): MambaOutStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=128, out_features=682, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (fc2): Linear(in_features=341, out_features=128, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): GatedConvBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1364, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (fc2): Linear(in_features=682, out_features=256, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): GatedConvBlock(\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2730, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MambaOutStage(\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(512, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): GatedConvBlock(\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (ls): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): MlpHead(\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (pre_logits): Sequential(\n",
       "      (fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (norm): LayerNorm((3072,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=3072, out_features=14, bias=True)\n",
       "    (head_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = model1(model=model, dataset=dataset, config=Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(trainer.dataset.label_df[\"class_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f655eddaaff4d6eb0fc71470a0aff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Fold 0, Epoch 0:   0%|          | 0/7219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(best_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[161], line 126\u001b[0m, in \u001b[0;36mTrainer.run_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(Subset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, val_indices), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_EPOCHS):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     _, val_acc, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(val_loader, epoch, fold)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_val_acc:\n",
      "Cell \u001b[0;32mIn[161], line 37\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self, train_loader, epoch, fold)\u001b[0m\n\u001b[1;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = trainer.run_training()\n",
    "\n",
    "torch.save(best_model, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.randn([4, 7, 7, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
